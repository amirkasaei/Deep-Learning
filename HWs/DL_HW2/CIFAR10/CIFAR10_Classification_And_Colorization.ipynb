{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAa6g3BcFCOi"
      },
      "source": [
        "# CIFAR10 Classification\n",
        "\n",
        "### HW2 @ DL Course, Dr. Soleymani\n",
        "\n",
        "*Full Name:* Seyed Amir Kasaei\n",
        "\n",
        "*SID:* 402212214\n",
        "\n",
        "In this part of the assignment we want to do an image classification task using PyTorch on CIFAR10 dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGfwMyZ7vm_f"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "Import needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GsrCzWTOIhI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIv1Mpsbvt8v"
      },
      "source": [
        "## Device\n",
        "\n",
        "Set device to work with (GPU or CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2uGuIUtwSFAR",
        "outputId": "65bfa875-e42c-4f6d-cc9f-bd4784361eb8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4T4AL0cv1Jm"
      },
      "source": [
        "## Transforms & Dataset & Dataloader\n",
        "\n",
        "Here, you should download and load the dataset with the desire transforms. After that, you should split train dataset to train and validation sets. Finally, define the dataloaders for `train`, `validation` and `test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E6TT8whO9N4"
      },
      "outputs": [],
      "source": [
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuo6wyCkEqMK"
      },
      "outputs": [],
      "source": [
        "transform_train = \n",
        "transform_test = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR0BpY0YO-Em"
      },
      "outputs": [],
      "source": [
        "# inverse the normilize transform to restore the original data\n",
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        return tensor\n",
        "\n",
        "norminv = UnNormalize(mean=(0.5, 0.5, 0.5), std=(0.20, 0.20, 0.20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3UuPXFQOSDX",
        "outputId": "cf4863a7-c4d2-408f-fce5-0c4641d83683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "initial_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61n36ZUkD-gA"
      },
      "outputs": [],
      "source": [
        "trainset, valset = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXhlMgGkEBPs"
      },
      "outputs": [],
      "source": [
        "trainloader = \n",
        "valloader = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "godQEnIuEDRo",
        "outputId": "8290ee12-13ad-4798-e5ff-5c03d7663387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C-YjLZtwnq2"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "Visualize 5 random images from each class in different columns\n",
        "\n",
        "- **Hint**:  You can use `plt.subplots` for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja-L0f1wybzU"
      },
      "source": [
        "## Model\n",
        "\n",
        "Define your ResNet model here from scratch (You are not allowed to use the existing models in pytorch)\n",
        "\n",
        "Our suggestion is to implement ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUYoc5gVVkTP"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ResNetBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "class ResNet18(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet18, self).__init__()\n",
        "        pass\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYp77Euaz_5u"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odR5mfCA0Eqy"
      },
      "source": [
        "### Model instantiation\n",
        "\n",
        "Create an instance of your model and move it to `device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3PjKY_oSBkg"
      },
      "outputs": [],
      "source": [
        "net = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8zn5eLs0bBS"
      },
      "source": [
        "### Criterion & Optimizater\n",
        "\n",
        "Define `criterion` and `optimizer` (Or `scheduler`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEd5yXt3SL2T"
      },
      "outputs": [],
      "source": [
        "criterion =\n",
        "optimizer = \n",
        "scheduler = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gth9e1k70uAI"
      },
      "source": [
        "### Train loop\n",
        "\n",
        "Train your model\n",
        "\n",
        "Tasks:\n",
        "- [ ] Things that are needed to be printed in each epoch:\n",
        "  - Number of epoch\n",
        "  - Train loss\n",
        "  - Train accuracy\n",
        "  - Validation loss\n",
        "  - Validation accuracy\n",
        "- [ ] save train/validation loss and accuracy (of each epoch) in an array for later usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONOcKjTxpDpQ"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFz0lVkUs8Mk"
      },
      "outputs": [],
      "source": [
        "def train_epoch(net: torch.nn.Module, criterion: torch.nn.Module, optimizer: torch.optim.Optimizer,scheduler: torch.optim.lr_scheduler ,dataloader: torch.utils.data.DataLoader):\n",
        "    pass\n",
        "\n",
        "def eval_epoch(net: torch.nn.Module, criterion: torch.nn.Module, dataloader: torch.utils.data.DataLoader, test_mode: bool = False):\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6Hm6VdzjEQA",
        "outputId": "c7b84570-c778-4e48-b417-5e947d041772"
      },
      "outputs": [],
      "source": [
        "epochs = \n",
        "\n",
        "for e in range(epochs):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwg7D6sv1kFL"
      },
      "source": [
        "### Visualize Loss and Accuracy plot\n",
        "\n",
        "Using the arrays that you have (from task 2 in the above section), visualize two plots: Accuracy plot (train and validation together) and Loss plot (train and validation together)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "zoTWbAVUbJw_",
        "outputId": "ef87523e-7135-4ec9-d335-7f9a705ff69b"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF_oCC3p2Q3C"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Test your trained model (using the Test Dataloader that you have). Our goal is to reach an accuracy above `80%`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzkNN4sMb3lK",
        "outputId": "bf964514-5db2-4acd-a0ef-a6e875b96f0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val: Loss: 5.163e-01 - Acc: 89.70%: 100%|██████████| 10/10 [00:03<00:00,  3.25it/s]\n"
          ]
        }
      ],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCKR1Xac2keH"
      },
      "source": [
        "## Visualize incorrectly predicted samples from testset\n",
        "\n",
        "Visualize *24* random images from testset that are incorrectly predicted by the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "Ew2KUBIWcG35",
        "outputId": "d76ece4b-c8fa-423c-f2fd-db6076bb1de6"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJdFFFGL9T7L"
      },
      "source": [
        "## Exploring the feature space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTQ0aX0j9c7q"
      },
      "source": [
        "### Calculate the feature space for all training samples\n",
        "\n",
        "You have trained and evaluated your model. Now, for each sample in the trainset, calculate it's \"feature space\" discussed in the model section. The result of this section should be a tensor of size `(50000, N)` saved in a variable (for later usage)\n",
        "\n",
        "- **Hint 1:** define a tensor with dimension `(50000, N)` where *50000* is the size of the trainset and *N* is the dimension of the feature space\n",
        "\n",
        "- **Hint 2:** Pay attension to the `shuffle` attribute of your train dataloader (If needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbMzEiuqyP20"
      },
      "outputs": [],
      "source": [
        "# TODO "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDoLqddo-WJV"
      },
      "source": [
        "### K Nearest Neighbor in feature space\n",
        "\n",
        "You already have calculated the feature spaces for trainset ($S$) in the previous section\n",
        "\n",
        "1. Get 5 random samples from testset which are correctly predicted by the model.\n",
        "2. for each sample, calculate it's \"feature space\" ($X$)\n",
        "3. for each sample, calculate it's *5* nearest neighbors in \"feature space\" in the trainset (by comparing $X$ to each row in $S$) and visualize them\n",
        "\n",
        "\n",
        "**Hint:** For finding the nearest neighbors in the feature space you can use `torch.linalg.norm` and `torch.topk`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "0IBf3Hbpb6mZ",
        "outputId": "ed247d9a-c0d0-4f27-9735-bb72a2f5d423"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X9aAFY3_g3w"
      },
      "source": [
        "### TSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3DC15RI_loC"
      },
      "source": [
        "1. Sample $M$ ($2000$ would be enought) random samples from the trainset feature space (calculated in the above sections)\n",
        "2. Now you have a vector of size `(M, N)` where $N$ is the dimension of the feature space\n",
        "3. Using TSNE reduce $N$ to $2$ (Now you have a vector of size `(M, 2)`)\n",
        "4. Visualize the points in a 2D plane (Set color of each point based on it's class)\n",
        "\n",
        "**Hint:** You can use `sklearn.manifold.TSNE`\n",
        "\n",
        "**Hint:** Use `plt.scatter(x, y, c=labels)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "qsj2zTP6XeLX",
        "outputId": "6f62fc22-e38b-4911-e57e-3e6e9f50db0c"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2NHVvUwF0-6"
      },
      "source": [
        "# CIFAR10 Colorization\n",
        "\n",
        "In this part of the assignment, we want to do an image colorization task using PyTorch on CIFAR10 dataset. We want to train a model that colors  a black-and-white image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-HuWeIBGlj1"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "Import needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2-QrdeQGlj2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JCj_e-J11kr_",
        "outputId": "9b874eb5-4aa9-499a-dfe9-47c6dc63c613"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vljvz3SpG_Hs"
      },
      "source": [
        "## Custom Dataset\n",
        "\n",
        "Define a custom dataset class by extensing `torch.utils.data.Dataset`\n",
        "\n",
        "**Notice:** your dataset should output two things: black-and-white image and the RGB image\n",
        "\n",
        "**Hint:** You don't have to reinvent the wheel. Your class should just be a wrapper for CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUfsSe7ZHAkv"
      },
      "outputs": [],
      "source": [
        "class BlackAndWhiteCIFAR10(Dataset):\n",
        "    \"\"\"\n",
        "    Define a custom dataset class by extending `torch.utils.data.Dataset`\n",
        "    this class is a dataset for the CIFAR10 data in pytorch and it has the black and white image of the original CIFAR10 image as the data\n",
        "    and the original RGB image as the target\n",
        "    this class is just a wrapper for the torchvision.datasets.CIFAR10 class\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, train=True, root='./data', download=True, transform=None):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqoRjKPAG1y2"
      },
      "source": [
        "## Transforms & Dataset & Dataloader\n",
        "\n",
        "**Notice:** Use your defined custom dataset class for defining the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obw3INKm1XJg"
      },
      "outputs": [],
      "source": [
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUyYOcG_G2_P"
      },
      "outputs": [],
      "source": [
        "transform_train = \n",
        "\n",
        "transform_test = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "84d3ef1673a549fa81117d5487a344e2",
            "50db6971d00842b4927f0179cde2e0f7",
            "3097c1869fb045b58cdfdf5d853c329d",
            "ebbb00f6f62a4a648baa9ea9c636e292",
            "c367441d96514be989291b3dd1c190c7",
            "00c651315a3543f3aa9268414c21f684",
            "743735a1426048aebbec54ef6ed46214",
            "3b06cce1a4494758b530b27c9a8ec233",
            "091df5377aa94c709d901bc836719bbc",
            "91db8ce9d6a14c53a855fb015d07d536",
            "a06813e829404414be23fcd3c8d24000"
          ]
        },
        "id": "WlvY-A0R1uow",
        "outputId": "045b3bcd-5cff-4c2c-cef8-988cf96d187e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84d3ef1673a549fa81117d5487a344e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "initial_trainset = BlackAndWhiteCIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPP5qwLo18hG"
      },
      "outputs": [],
      "source": [
        "trainset, valset = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkYNF8ah19LX"
      },
      "outputs": [],
      "source": [
        "trainloader = \n",
        "valloader = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Nz6IWxINoq"
      },
      "source": [
        "## Dataset Visualization\n",
        "\n",
        "Visualize your dataset (black-and-white image along with the RGB image) by sampling from your trainset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "hjj-B6SSIPTU",
        "outputId": "b24a4ff0-1db4-4c11-ab96-f12b6d2e8d16"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYXibse_I6Sw"
      },
      "source": [
        "## Model\n",
        "\n",
        "Define your model here (Input: black-and-white image, Output: RGB image)\n",
        "\n",
        "**Hint:** You can implement an autoencoder that does the colorization task for you. UNet could be a viable option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrAaIwPYI5Lp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "class TransConvBlock(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(TransConvBlock, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, skip_input):\n",
        "        pass\n",
        "\n",
        "class colorizationNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox3GdhWkKSfy"
      },
      "source": [
        "## Train\n",
        "\n",
        "Train your model\n",
        "\n",
        "Tasks:\n",
        "- [ ] Things that are needed to be printed in each epoch:\n",
        "  - Number of epoch\n",
        "  - Train loss\n",
        "  - Validation loss\n",
        "- [ ] save train/validation loss (of each epoch) in an array for later usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLH9z2zjKjEH"
      },
      "outputs": [],
      "source": [
        "net = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3Q3WylJnrpc"
      },
      "outputs": [],
      "source": [
        "criterion = \n",
        "optimizer = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrnVWkAypq3-"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTvVBSOtqIX8"
      },
      "outputs": [],
      "source": [
        "def train_epoch(net: torch.nn.Module, criterion: torch.nn.Module, optimizer: torch.optim.Optimizer ,dataloader: torch.utils.data.DataLoader):\n",
        "    pass\n",
        "\n",
        "def eval_epoch(net: torch.nn.Module, criterion: torch.nn.Module, dataloader: torch.utils.data.DataLoader, test_mode: bool = False):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOoWOGuGqNbZ",
        "outputId": "0e8e002d-591c-48b4-8367-149e2a2cd3f9"
      },
      "outputs": [],
      "source": [
        "epochs = \n",
        "\n",
        "for e in range(epochs):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEM_ntRJLjLR"
      },
      "source": [
        "### Visualize Loss plot\n",
        "\n",
        "Using the arrays that you have (from task 2 in the above section), visualize the loss plot (train and validation together)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "pesG4263qeU2",
        "outputId": "4d79e486-740a-47b6-c7ca-2a6236c1d1c6"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekWfxMkpKot4"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "1. Sample 36 random samples from testset (your own dataset class)\n",
        "2. Give each of the 36 samples to your trained model and get the outputs\n",
        "3. Visualize `input` (black-and-white image), `output` (output of the model with the given black-and-white input image) and `ground truth` (the actual RGB image)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8lhDXtgvqQl",
        "outputId": "6240684b-f76e-4efd-f51f-8f304aeace09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "testset =\n",
        "testloader = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9BjzM16yZgg"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "dff97b9f14a22ccae10e7a517c30d03fcee05a8617da6e3ca20a923077f5eb08"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00c651315a3543f3aa9268414c21f684": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "091df5377aa94c709d901bc836719bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3097c1869fb045b58cdfdf5d853c329d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b06cce1a4494758b530b27c9a8ec233",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_091df5377aa94c709d901bc836719bbc",
            "value": 170498071
          }
        },
        "3b06cce1a4494758b530b27c9a8ec233": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50db6971d00842b4927f0179cde2e0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00c651315a3543f3aa9268414c21f684",
            "placeholder": "​",
            "style": "IPY_MODEL_743735a1426048aebbec54ef6ed46214",
            "value": "100%"
          }
        },
        "743735a1426048aebbec54ef6ed46214": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d3ef1673a549fa81117d5487a344e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50db6971d00842b4927f0179cde2e0f7",
              "IPY_MODEL_3097c1869fb045b58cdfdf5d853c329d",
              "IPY_MODEL_ebbb00f6f62a4a648baa9ea9c636e292"
            ],
            "layout": "IPY_MODEL_c367441d96514be989291b3dd1c190c7"
          }
        },
        "91db8ce9d6a14c53a855fb015d07d536": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a06813e829404414be23fcd3c8d24000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c367441d96514be989291b3dd1c190c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebbb00f6f62a4a648baa9ea9c636e292": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91db8ce9d6a14c53a855fb015d07d536",
            "placeholder": "​",
            "style": "IPY_MODEL_a06813e829404414be23fcd3c8d24000",
            "value": " 170498071/170498071 [00:01&lt;00:00, 87093789.07it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
